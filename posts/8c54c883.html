<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深度学习概览 | 炊煙雲海。</title><meta name="author" content="LanC1oud"><meta name="copyright" content="LanC1oud"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Deep Learning.">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习概览">
<meta property="og:url" content="http://lanc1oud.top/posts/8c54c883.html">
<meta property="og:site_name" content="炊煙雲海。">
<meta property="og:description" content="Deep Learning.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://lanc1oud.top/img/avatar.png">
<meta property="article:published_time" content="2025-12-21T03:26:07.000Z">
<meta property="article:modified_time" content="2025-12-21T07:17:03.976Z">
<meta property="article:author" content="LanC1oud">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://lanc1oud.top/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深度学习概览",
  "url": "http://lanc1oud.top/posts/8c54c883.html",
  "image": "http://lanc1oud.top/img/avatar.png",
  "datePublished": "2025-12-21T03:26:07.000Z",
  "dateModified": "2025-12-21T07:17:03.976Z",
  "author": [
    {
      "@type": "Person",
      "name": "LanC1oud",
      "url": "http://lanc1oud.top"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lanc1oud.top/posts/8c54c883.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.3-b2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习概览',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 8.1.1"></head><body><div class="bg-animation" id="web_bg" style="background-image: url(/img/background.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: transparent;"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">炊煙雲海。</span></a><a class="nav-page-title" href="/"><span class="site-name">深度学习概览</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">深度学习概览</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-21T03:26:07.000Z" title="发表于 2025-12-21 11:26:07">2025-12-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-12-21T07:17:03.976Z" title="更新于 2025-12-21 15:17:03">2025-12-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">569</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="from-linear-regression-exhaustive-search"><a class="markdownIt-Anchor" href="#from-linear-regression-exhaustive-search"></a> From Linear Regression: Exhaustive Search</h2>
<img src="/posts/8c54c883/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E7%A9%B7%E4%B8%BE%E6%B3%95.png" class="" title="穷举法">
<ul>
<li>Prepare the train set.</li>
<li>Define the model: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>h</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>x</mi><mo>∗</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">y_{hat} = x * w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>.</li>
<li>Define the loss funciton: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>h</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>∗</mo><mi>w</mi><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">loss = (y_{hat} - y)^2 = (x * w - y)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>.</li>
<li>List <code>w_list</code> save the weights <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span></span></strong><br />
List <code>mse_list</code> save the <strong>cost values of each <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span></span></strong>.</li>
<li>Compute cost value at (0.0,4.0,0.1)</li>
<li><strong>Value of cost function is the sum of loss function</strong></li>
</ul>
<p>Find the min_loss.</p>
<h2 id="gradient-descent梯度下降算法"><a class="markdownIt-Anchor" href="#gradient-descent梯度下降算法"></a> Gradient Descent(梯度下降算法)</h2>
<img src="/posts/8c54c883/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.png" class="" title="梯度下降">
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> is for learning rate.</p>
<p>Use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>x</mi><mo>∗</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">y = x * w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> as example:</p>
<img src="/posts/8c54c883/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.png" class="" title="梯度下降">
<p>code and result:</p>
<img src="/posts/8c54c883/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.png" class="" title="梯度下降">
<ul>
<li>Define the cost function:<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>h</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">cost = \sum_{i=1}^n (y_{hat} - y)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>Define the gardient function:<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>ω</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mn>2</mn><mo>⋅</mo><msub><mi>x</mi><mi>n</mi></msub><mo>⋅</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo>⋅</mo><mi>ω</mi><mo>−</mo><msub><mi>y</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial cost}{\partial \omega} = \frac{1}{N} \sum_{n=1}^{N} 2 \cdot x_n \cdot (x_n \cdot \omega - y_n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.59445em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
<li>Do the update:<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>ω</mi><mo>=</mo><mi>ω</mi><mo>−</mo><mi>α</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>ω</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\omega = \omega - \alpha\frac{\partial cost}{\partial \omega}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
<p>Use <strong>Stochastic Gradient Descent</strong>(随机梯度下降) to replace the normal: escape hte <strong>Saddle Points</strong>(but high Time Complexity)</p>
<img src="/posts/8c54c883/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D4.png" class="" title="梯度下降">
<p>Use <strong>Batch</strong> or <strong>Mini-Batch</strong>(批量梯度下降) to balance Time Complexity and Correct Rate.</p>
<h2 id="back-propagation反向传播"><a class="markdownIt-Anchor" href="#back-propagation反向传播"></a> Back Propagation(反向传播)</h2>
<h3 id="neural-networks"><a class="markdownIt-Anchor" href="#neural-networks"></a> Neural Networks</h3>
<p>Complicated net work:</p>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD1.png" class="" title="反向传播">
<p>Still a simple example:</p>
<p>Derivative</p>
<p>Nonlinear Function(激活函数):Introduce non-linearity into neural networks.</p>
<h3 id="backward"><a class="markdownIt-Anchor" href="#backward"></a> Backward</h3>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD3.png" class="" title="反向传播">
<p>Actually:Derivative’s Chain Rules</p>
<p>Still a simple example:</p>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD4.png" class="" title="反向传播">
<h2 id="in-pytorch"><a class="markdownIt-Anchor" href="#in-pytorch"></a> in PyTorch</h2>
<p>In PyTorch, Tensor is the important component in constructing dynamic computational graph.</p>
<p>It contains Data and Grad, which storage the value of node and gradient w.r.t loss respectively.</p>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD5.png" class="" title="反向传播">
<p>If autograd mechanics are required, the element variable requires_grad of Tensor has to be <strong>True</strong></p>
<p>Model:</p>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD6.png" class="" title="反向传播">
<ul>
<li>Define the linear model and the loss function.</li>
</ul>
<img src="/posts/8c54c883/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD7.png" class="" title="反向传播">
<ul>
<li>Forward, compute the loss.</li>
<li>Backward, compute the grad for Tensor whose requires_grad set to True.</li>
<li>The grad is utilized to update weight.</li>
<li>NOTICE:
<ul>
<li>The grad computed by <code>.backward()</code> will be accumulated.</li>
<li>So after update, remember set the grad to <strong>ZERO</strong>!</li>
</ul>
</li>
</ul>
<h3 id="linear-regression-with-pytorch"><a class="markdownIt-Anchor" href="#linear-regression-with-pytorch"></a> Linear Regression with PyTorch</h3>
<ol>
<li>Prepare dataset</li>
<li>Design model using Class: inherit form nn.Module</li>
<li>Construct loss and optimizer: using PyTorch API</li>
<li>Training cycle: forward, backward, update</li>
</ol>
<p>Code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare dataset</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>],[<span class="number">4.0</span>],[<span class="number">6.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Design model using Class</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearModel</span>(torch.nn.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>(LinearModel,<span class="variable language_">self</span>).__init__()</span><br><span class="line">    <span class="variable language_">self</span>.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Class nn.Linear contains two members Tensors: Weight and Bias</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">    y_pred = <span class="variable language_">self</span>.linear(x)</span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line">model = LinearModel()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct loss and optimizer</span></span><br><span class="line">criterion = torch.nn.MSELoss(size_average=<span class="literal">False</span>,reduce=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training cycle</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">  y_pred = model(x_data)</span><br><span class="line">  loss = criterion(y_pred,y_data) <span class="comment"># forward</span></span><br><span class="line">  <span class="built_in">print</span>(epoch,loss.item())</span><br><span class="line"></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line">  loss.backward() <span class="comment"># backward</span></span><br><span class="line">  optimizer.step() <span class="comment"># update</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>,model.linear.weight.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>,model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred = &#x27;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
<p>optimizer in PyTorch:</p>
<ul>
<li>torch.optim.Adagrad</li>
<li>torch.optim.Adam</li>
<li>torch.optim.Adamax</li>
<li>torch.optim.ASGD</li>
<li>torch.optim.LBFGS</li>
<li>torch.optim.RMSprop</li>
<li>torch.optim.Rprop</li>
<li>torch.optim.SGD</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://lanc1oud.top">LanC1oud</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://lanc1oud.top/posts/8c54c883.html">http://lanc1oud.top/posts/8c54c883.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://lanc1oud.top" target="_blank">炊煙雲海。</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/ff904a85.html" title="离散数学II概览"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">离散数学II概览</div></div><div class="info-2"><div class="info-item-1">与其说是概览，更像是概念和定理的摘抄总结</div></div></div></a><a class="pagination-related" href="/posts/ae6d8d24.html" title="NumPy"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">NumPy</div></div><div class="info-2"><div class="info-item-1">自用。</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/ae6d8d24.html" title="NumPy"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-19</div><div class="info-item-2">NumPy</div></div><div class="info-2"><div class="info-item-1">自用。</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">LanC1oud</div><div class="author-info-description">循此苦旅，以达繁星。</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LanC1oud"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">复习期末中......</div></div><div class="card-widget card-music"><div class="card-content"><div class="item-headline"><i class="fa fa-music" aria-hidden="true"></i><span>Music</span></div><div class="aplayer" data-id="8628903830" data-server="netease" data-type="playlist" data-fixed="false" data-autoplay="true" data-listmaxheight="350px" data-theme="#49b1f5" data-order="random" data-preload="auto"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#from-linear-regression-exhaustive-search"><span class="toc-number">1.</span> <span class="toc-text"> From Linear Regression: Exhaustive Search</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gradient-descent%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text"> Gradient Descent(梯度下降算法)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#back-propagation%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">3.</span> <span class="toc-text"> Back Propagation(反向传播)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#neural-networks"><span class="toc-number">3.1.</span> <span class="toc-text"> Neural Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backward"><span class="toc-number">3.2.</span> <span class="toc-text"> Backward</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#in-pytorch"><span class="toc-number">4.</span> <span class="toc-text"> in PyTorch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#linear-regression-with-pytorch"><span class="toc-number">4.1.</span> <span class="toc-text"> Linear Regression with PyTorch</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/ff904a85.html" title="离散数学II概览">离散数学II概览</a><time datetime="2025-12-23T03:46:17.000Z" title="发表于 2025-12-23 11:46:17">2025-12-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/8c54c883.html" title="深度学习概览">深度学习概览</a><time datetime="2025-12-21T03:26:07.000Z" title="发表于 2025-12-21 11:26:07">2025-12-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/ae6d8d24.html" title="NumPy">NumPy</a><time datetime="2025-12-18T16:12:12.000Z" title="发表于 2025-12-19 00:12:12">2025-12-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/531b2dcd.html" title="MySQL简单教程">MySQL简单教程</a><time datetime="2025-12-16T15:33:41.000Z" title="发表于 2025-12-16 23:33:41">2025-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f80d473d.html" title="[炽吾生平]初雪记"><img src="/img/cover_xue.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="[炽吾生平]初雪记"/></a><div class="content"><a class="title" href="/posts/f80d473d.html" title="[炽吾生平]初雪记">[炽吾生平]初雪记</a><time datetime="2025-12-12T16:54:12.000Z" title="发表于 2025-12-13 00:54:12">2025-12-13</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By LanC1oud</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3-b2</a></span></div><div class="footer_custom_text">Hi,welcome to LanC1oud's Blog.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3-b2"></script><script src="/js/main.js?v=5.5.3-b2"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"emojiCDN":"//i0.hdslb.com/bfs/emote/","emojiMaps":{"tvgif-白眼":"48f75163437445665a9be80bb316e4cb252c5415.gif","tvgif-doge":"302d6c88c63ed162c81a49cafe7ed2709e6fb955.gif","tvgif-坏笑":"5d2572efd09aab5dde9e2a198bb3f9ac1e2a982e.gif","tvgif-难过":"9c6b41008a67755410f712334c64313df5f91b3f.gif","tvgif-生气":"1902a5a2df5b5c931d88c12f0feb264b1e109d0d.gif","tvgif-委屈":"af5a5853edb43a8178a8cb5df707fa5e88143699.gif","tvgif-斜眼笑":"c66568b471192ca1f62f6ed4384dc1b283ab7508.gif","tvgif-呆":"d3fa91e4db9215eb1e20ab9da44f1214aa4bda7b.gif","tvgif-发怒":"3959eb81b952e4fa8d269d98f9e3639172d84073.gif","tvgif-惊吓":"13549060757fcd92b11d0657d9b3b6038f97abb6.gif","tvgif-呕吐":"db58e9442aae26694af18cc1683607cca3a16763.gif","tvgif-思考":"b63f9146bfd985af014f8d6d4bdb498805be48f9.gif","tvgif-微笑":"b98656855d782f61cb8edc7f7fca6563ecafff7e.gif","tvgif-疑问":"fce1b1a0f3b0e39a2dc16a18508dba7b91e929f4.gif","tvgif-大哭":"cba61f05f3039b02a7ffc0dfcd9d7995df9fdd74.gif","tvgif-鼓掌":"be106e6b265883a9f28fbe10f7b765701e2618d4.gif","tvgif-抠鼻":"696d9f93e722144dc2a78aeffc569418fdf3d565.gif","tvgif-亲亲":"3534ea44ab74bd20352b88c245a06c4b4c46d271.gif","tvgif-调皮":"fcd967395fd14e4dd5829fa7e8a967ce23205e52.gif","tvgif-笑哭":"1c2fd1e8c9dde12812f86e5d4cbddd8993d98082.gif","tvgif-晕":"030040ec5c9ddc9e3d067658c4139e7314ab42f8.gif","tvgif-点赞":"30ecff401245fb56bcc1cf588d1809ac1ab1607c.gif","tvgif-害羞":"411a3e459e8580f5bfd9f639a408247c4b509935.gif","tvgif-睡着":"3c8b5e293261287a6203597e29b3de07df4d18c6.gif","tvgif-色":"a0c6d99ab0ab63b8648f5283ff72cec04b604828.gif","tvgif-吐血":"e17e4539e169d14a3389ff147afea760cebe5de5.gif","tvgif-无奈":"eb4cb5f07cfd177c7e6a7914316717e56d9cc1d0.gif","tvgif-再见":"344f61609ecce2008520dc8a977b6169215748a9.gif","tvgif-流汗":"390bccec65eaff536bd5bb2a0c5b8b0bdea47334.gif","tvgif-偷笑":"7f11e6f7f63e79112b833bd41fa13a83d7cd8474.gif","tvgif-抓狂":"a476b93ecd8e94ac3257323fd822f91cef212de2.gif","tvgif-黑人问号":"b609adf664be33224a9923262031165ae3e34cd2.gif","tvgif-困":"91c2bf34ecf842d7016c01d841db3d4074bd281f.gif","tvgif-打脸":"b0fad4856e59c1240e448437da3287bb5ce547e5.gif","tvgif-闭嘴":"a3fc5388b09e945be3f18fe23bfed5874a0285b7.gif","tvgif-鄙视":"293b5d459e6264ecf314d20937a936fa672ccd1e.gif","tvgif-腼腆":"30984e8264324f901d19bea85dada7103b695534.gif","tvgif-馋":"2525c5703c594e5f0752f68db8948773caebde47.gif","tvgif-可爱":"f92d20f76258bc5f33fc9d7c5e2a1d41fef19a7c.gif","tvgif-发财":"76131e52c9b033681b4c896c6024d29ef7ec7ec2.gif","tvgif-生病":"beb94829fe04f1a41bd6ca611e1f6ca9ca169afa.gif","tvgif-流鼻血":"8ef473f74a849420da712487b2f56ecca1f695f5.gif","tvgif-尴尬":"e0b84ef5ee3e5b8978e584c7c5a6550c51d15f84.gif","tvgif-大佬":"14ca0c05382b8741940942b2430b7a8d55c02f7e.gif","2233娘-大笑":"16b8794be990cefa6caeba4d901b934a227ee3b8.png","2233娘-吃惊":"d1628c43d35b1530c0504a643ff80b6189fa0a43.png","2233娘-大哭":"476a2a60f6e337b8c0697a592e0aa82781f6b33b.png","2233娘-耶":"d7178e258a0efc969b65ccc2b1322fb235f5dff4.png","2233娘-卖萌":"ea893aa25355de95ab4f03c2dad3f0c58d0c159e.png","2233娘-疑问":"0b41f509351958dbb63d472fec0132d1bd03bd14.png","2233娘-汗":"247cd9df8cdf84b18368c21e3b2dd374e84c0927.png","2233娘-困惑":"714eeb4eae0d0933b4ff08b7df788b1982f6b940.png","2233娘-怒":"f31953119c51b9748016440ac0b632f779929b37.png","2233娘-委屈":"d9d0bf9d358af8d5761093ec66d4e3f60d963a63.png","2233娘-郁闷":"485203fe7100f2c8fc40b2800a18fe20b35f2f1a.png","2233娘-第一":"3754ee6e5985bd0bd7dfb668981f2a8733398ebd.png","2233娘-喝水":"695bf5429472049b52c1e0de586f8a2511195a23.png","2233娘-吐魂":"e999af499edf38a91ca68b1a9d2f97042c1d6734.png","2233娘-无言":"fdb5870f32cfaf7949e0f88a13f6feba4a48b719.png","明日方舟-喷喷":"10e7f252d5106d46cb47c666e4c2e693bfa66959.png","明日方舟-溜了":"a103c00f0f4be3bd674723802d712980196817f4.png","明日方舟-嘿嘿":"14dd3de8f576204ee6d9c4948f8fa360ae82041c.png","明日方舟-怎么回事":"6cb24d88e87d34584350559fb92da9104ad14d77.png","明日方舟-吃瓜":"b0c87e42fdb27b6683a3ae873a89383e789a38f3.png","明日方舟-不可以哦":"1a4e9cfe14ca3d5e35e25671f1dd3451d0f1e562.png","明日方舟-喧嚣的风":"c4d1b6fb903d2e6d74c0ab0a31029fe184c95c14.png","明日方舟-哭了":"553937828ebbacd15edb7f4c8b0d6ff94b2aafd0.png","明日方舟-不好意思":"9a411c1930b4679fd5ef5419ce5268c4271efe5c.png","明日方舟-一下就好":"7ec17d337981a9a01062160812324289801ed78c.png","音律联觉-得意":"5e47efce45e661421b7b779f6096880d4f6862e5.png","音律联觉-点赞":"0ad4f2f6268522168917ffa1c1fd41947867f74d.png","音律联觉-哈欠":"77ea4ecc3ac14eaf530de59a97fb3ce0286f05e1.png","音律联觉-喝茶":"bd9883a889255e2b83bb01e069010ad589c83d3a.png","音律联觉-就是你了":"afc63cf67ecdf2830c3e68d3cc699283c4857093.png","音律联觉-可爱":"9bc0aeb667bbbbc84ecf89c31dc55dd5723d3d7b.png","音律联觉-热情":"a69b8c25a31eb48ade5e2bae67e486643ce83c0a.png","音律联觉-叹气":"36bdbed295863819755fafae7780518776cc5d82.png","音律联觉-无奈":"18782bd913430403c666678feb02da2ee2b7ad05.png","音律联觉-正在记录":"289af83b268e40f22a93aa62d995d4649f7000f7.png"}}

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: 'sq3wVI8fj6VJ6fUKlDmjWLI9-gzGzoHsz',
      appKey: '1GPTY2QZUaWKMSLXg7UYXhQe',
      avatar: 'identicon',
      serverURLs: '',
      emojiMaps: {"tv_doge":"tv_doge.png","tv_亲亲":"tv_qinqin.png","tv_偷笑":"tv_touxiao.png","tv_再见":"tv_zaijian.png","tv_冷漠":"tv_lengmo.png","tv_发怒":"tv_fanu.png","tv_发财":"tv_facai.png","tv_可爱":"tv_keai.png","tv_吐血":"tv_tuxue.png","tv_呆":"tv_dai.png","tv_呕吐":"tv_outu.png","tv_困":"tv_kun.png","tv_坏笑":"tv_huaixiao.png","tv_大佬":"tv_dalao.png","tv_大哭":"tv_daku.png","tv_委屈":"tv_weiqu.png","tv_害羞":"tv_haixiu.png","tv_尴尬":"tv_ganga.png","tv_微笑":"tv_weixiao.png","tv_思考":"tv_sikao.png","tv_惊吓":"tv_jingxia.png","tv_打脸":"tv_dalian.png","tv_抓狂":"tv_zhuakuang.png","tv_抠鼻":"tv_koubi.png","tv_斜眼笑":"tv_xieyanxiao.png","tv_无奈":"tv_wunai.png","tv_流汗":"tv_liuhan.png","tv_流鼻血":"tv_liubixue.png","tv_点赞":"tv_dianzan.png","tv_生气":"tv_shengqi.png","tv_生病":"tv_shengbing.png","tv_白眼":"tv_baiyan.png","tv_皱眉":"tv_zhoumei.png","tv_目瞪口呆":"tv_mudengkoudai.png","tv_睡着":"tv_shuizhe.png","tv_笑哭":"tv_xiaoku.png","tv_腼腆":"tv_miantian.png","tv_色":"tv_se.png","tv_调侃":"tv_tiaokan.png","tv_调皮":"tv_tiaopi.png","tv_鄙视":"tv_bishi.png","tv_闭嘴":"tv_bizui.png","tv_难过":"tv_nanguo.png","tv_馋":"tv_chan.png","tv_鬼脸":"tv_guilian.png","tv_黑人问号":"tv_heirenwenhao.png","tv_鼓掌":"tv_guzhang.png"},
      visitor: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine@1.5.3/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      true
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>